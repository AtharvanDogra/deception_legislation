{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.read_csv('dataset_building/8_11_14_18.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_id=[]\n",
    "beg_id=[]\n",
    "\n",
    "for i, cong in enumerate([114,116, 118]):\n",
    "    prev_idx = int(gt_112_data[gt_112_data.congress == cong-1].iloc[-1].name)\n",
    "    # prev_id.append(prev_idx)\n",
    "    \n",
    "    # beg_idx = int(fourteen_18_data[fourteen_18_data.congress == cong].iloc[0].name)\n",
    "    # beg_id.append(beg_idx)\n",
    "    gt_112_data = pd.concat([gt_112_data[:prev_idx+1], fourteen_18_data[fourteen_18_data.congress==cong], gt_112_data[prev_idx+1:]]).reset_index(drop=True)\n",
    "    # next_idx = int(gt_112_data[gt_112_data.congress == cong+1].iloc[0].name) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[59, 440, 965, 1096, 1682, 2050, 2170]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_ind = []\n",
    "for i in [108, 109, 110, 111, 114, 116, 118]: # range(108, 119):\n",
    "    last_idx = data[data.congress==i].iloc[-1].name\n",
    "    last_ind.append(last_idx)\n",
    "last_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[59, 440, 965, 1482, 1968, 2528, 3114, 3536, 3904, 4318, 4438]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('dataset_building/last_inds.json', 'r') as f:\n",
    "    last_ind = json.load(f)['last_ind']\n",
    "last_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('memory/qwen_run_8_11/detection.json', 'r+') as f:\n",
    "    eight_el = json.load(f)\n",
    "# with open('memory/yi_run_gt112/detection.json', 'r+') as f:\n",
    "#     gt_112 = json.load(f)\n",
    "with open('memory/qwen_run_14_16_18/detection.json', 'r+') as f:\n",
    "    fourteen_118 = json.load(f)\n",
    "with open('memory/qwen_run_gt112/detection.json', 'r+') as f:\n",
    "    gt_112 = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to get results from incomplete 8_11 run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "eight_11_incomp_14_18 = pd.concat([eight_11.iloc[:eight_el_main.keys().__len__()], fourteen_18]).reset_index(drop=True)\n",
    "# eight_11_incomp_14_18.to_csv('dataset_building/eight_11_incomp_14_18.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for those where i missed updating count while resuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('memory/mixtral_cot_run_14_16_18/main.json', 'r+') as f:\n",
    "    fourteen_118_main = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "detected = []\n",
    "for i in range(1074):\n",
    "    keys = list(fourteen_118_main[str(i)].keys())\n",
    "    keys.remove('benefactor')\n",
    "    \n",
    "    assert keys.__len__()<4\n",
    "    \n",
    "    if keys.__len__() == 1:\n",
    "        detected.append(0)\n",
    "    elif keys.__len__() == 2:\n",
    "        detected.append(1)\n",
    "    elif keys.__len__() == 3:\n",
    "        if fourteen_118_main[str(i)]['2']['detected']:\n",
    "            detected.append(3)\n",
    "        else:\n",
    "            detected.append(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_detection = np.concatenate([np.array(eight_el), np.array(gt_112)[:gaps['gt_112_gap_prev'][0]], np.array(fourteen_118)[:gaps['14_18_gaps_begin'][1]], np.array(gt_112)[gaps['gt_112_gap_prev'][0]:gaps['gt_112_gap_prev'][1]], \n",
    "                np.array(fourteen_118)[gaps['14_18_gaps_begin'][1]:gaps['14_18_gaps_begin'][2]], np.array(gt_112)[gaps['gt_112_gap_prev'][1]:], np.array(fourteen_118)[gaps['14_18_gaps_begin'][2]:]\n",
    "              ])#.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('detection_results/qwen_detection.json', 'w') as f:\n",
    "#     json.dump(full_detection.tolist(), f, indent=4)\n",
    "with open('memory/robustness_trial/qwen14_run_14_16_18_200_rob_ablate_comp/detection.json', 'r') as f:\n",
    "    full_detection = json.load(f)\n",
    "\n",
    "dt = np.array(full_detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt[:, :, 0].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### top-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "detection_top1_all_models = {}\n",
    "# for model in ['mistral7instructV2', 'qwen7', 'qwen14', 'yi34Chat', 'mixtral', 'qwen']:\n",
    "for model in ['qwen14']:\n",
    "    \n",
    "    # with open(f'detection_results/{model}_detection.json', 'r') as f:\n",
    "    with open(f'memory/constant_critic/smaller_14/qwen/poll_pairs_three_llms/poll_pairs/detection_14_500.json', 'r') as f:\n",
    "        full_detection = json.load(f)\n",
    "\n",
    "    dt = np.array(full_detection)\n",
    "\n",
    "    for i in range(dt[:, :, 0].shape[0]):\n",
    "        for j in range(dt[i, :, 0].shape[0]-2, -1, -1):\n",
    "            if not dt[i, :, 0][j]:\n",
    "                dt[i, :, 0][j:] = 0\n",
    "\n",
    "    dt_top1 = dt[:, :, 0].copy()\n",
    "    \n",
    "    detection_per_trial = []\n",
    "    for i in range(3):\n",
    "        detection_per_trial.append(dt_top1[:, i].mean())\n",
    "    # if model == 'qwen':\n",
    "    #     detection_per_trial.append(dt_top1[:, 3].mean())\n",
    "    detection_top1_all_models[model] = detection_per_trial\n",
    "\n",
    "detection_top1_all_models\n",
    "\n",
    "# with open('detection_results/qwen14_poll_pair_three_llm.json', 'w') as f:\n",
    "#     json.dump(detection_top1_all_models, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### top-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'memory/qwen14_run_14_16_18/detection.json', 'r') as f:\n",
    "    full_detection = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7970204841713222, 0.6340782122905028, 0.5726256983240223]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "det_results = []\n",
    "for i in range(3): \n",
    "    det_results.append(np.array(full_detection)[:, i].sum(-1).mean())\n",
    "    \n",
    "det_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('memory/constant_critic/larger/qwen14_run_14_16_18/top2_results.json', 'w') as f:\n",
    "    json.dump(det_results, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "gt = []\n",
    "percents = []\n",
    "for i in range(3):\n",
    "    gt.append(np.count_nonzero(np.int32(dt.sum(1).sum(-1) > i)))#, np.count_nonzero(np.int32(dt_cot.sum(1).sum(-1) > 2))\n",
    "    percents.append(gt[i]/dt.shape[0])\n",
    "    \n",
    "# with open('dataset_building/last_inds.json', 'r') as f:\n",
    "#     last_ind = json.load(f)['last_ind']\n",
    "\n",
    "\n",
    "cong_gt = []\n",
    "cong_percents = []\n",
    "lst = [-1] + last_ind\n",
    "ranges = [[lst[i]+1, lst[i+1]+1] for i in range(len(lst)-1)]\n",
    "for r in ranges:\n",
    "    cong_gt += [[]]\n",
    "    cong_percents += [[]]\n",
    "    cong_dt = dt[r[0]:r[1]]\n",
    "    for i in range(3):\n",
    "        cong_gt[-1].append(np.count_nonzero(np.int32(cong_dt.sum(1).sum(-1) > i)))\n",
    "        # cong_gt[-1].append(np.count_nonzero(np.int32(cong_dt > i)))\n",
    "        \n",
    "        cong_percents[-1].append(cong_gt[-1][i]/cong_dt.shape[0])\n",
    "\n",
    "results['gt'] = gt\n",
    "results['percents'] = percents\n",
    "results['cong_gt'] = cong_gt\n",
    "results['cong_percents'] = cong_percents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = data.state.unique()\n",
    "state_ind = {}\n",
    "for s in states:\n",
    "    state_ind[s] = data[data.state==s].index\n",
    "# state_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_gt = {}\n",
    "state_percents = {}\n",
    "\n",
    "for k,v in state_ind.items():\n",
    "    state_gt[k] = []\n",
    "    state_percents[k] = []\n",
    "    for i in range(3):\n",
    "        state_gt[k] += [np.count_nonzero(np.int32(dt[v].sum(1).sum(-1) > i))]\n",
    "        # state_gt[k] += [np.count_nonzero(np.int32(dt[v] > i))]\n",
    "        \n",
    "        state_percents[k] += [state_gt[k][i]/dt[v].shape[0]]\n",
    "        \n",
    "results['state_gt'] = state_gt\n",
    "results['state_percents'] = state_percents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = [a for a in data.policyArea.unique() if a is not np.nan]\n",
    "policy_ind = {}\n",
    "for p in policy:\n",
    "    policy_ind[p] = data[data.policyArea==p].index\n",
    "\n",
    "policy_gt = {}\n",
    "policy_percents = {}\n",
    "\n",
    "for k,v in policy_ind.items():\n",
    "    policy_gt[k] = []\n",
    "    policy_percents[k] = []\n",
    "    for i in range(3):\n",
    "        policy_gt[k] += [np.count_nonzero(np.int32(dt[v].sum(1).sum(-1) > i))]\n",
    "        # policy_gt[k] += [np.count_nonzero(np.int32(dt[v]) > i)]\n",
    "        \n",
    "        policy_percents[k] += [policy_gt[k][i]/dt[v].shape[0]]\n",
    "        \n",
    "results['policy_gt'] = policy_gt\n",
    "results['policy_percents'] = policy_percents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('detection_results/yiChat_8_11_incomp_14_16_18_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gu, pr, as → territories, not states\\\n",
    "dc → district (washinton dc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Top 1 states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "with open(f'memory/qwen_run_8_11/detection.json', 'r') as f:\n",
    "    dt = np.array(json.load(f))\n",
    "    \n",
    "data = pd.read_csv('dataset_building/8_11/selected_8_11_policya_state.csv')\n",
    "\n",
    "state_detections = {}\n",
    "\n",
    "for i in range(dt[:, :, 0].shape[0]):\n",
    "        for j in range(dt[i, :, 0].shape[0]-2, -1, -1):\n",
    "            if not dt[i, :, 0][j]:\n",
    "                dt[i, :, 0][j:] = 0\n",
    "                \n",
    "dt_top1 = dt[:, :3, 0].copy()\n",
    "\n",
    "for state, det in zip(data.state, dt_top1):\n",
    "    state_detections[state] = state_detections.get(state, []) + [det.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "datamap = {'8_11':'dataset_building/8_11/selected_8_11_policya_state.csv',\n",
    "           'gt112': 'dataset_building/gt112_except14_16_18/gt112_policya_state.csv',\n",
    "           '14_16_18': 'dataset_building/14_16_18/14_16_18_policya_state.csv'}\n",
    "\n",
    "state_detections = {}\n",
    "state_detection_percents = {}\n",
    "\n",
    "for split in ['8_11', 'gt112', '14_16_18']:\n",
    "    with open(f'memory/qwen_run_{split}/detection.json', 'r') as f:\n",
    "        dt = np.array(json.load(f))\n",
    "\n",
    "    data = pd.read_csv(datamap[split])\n",
    "    \n",
    "    for i in range(dt[:, :, 0].shape[0]):\n",
    "        for j in range(dt[i, :, 0].shape[0]-2, -1, -1):\n",
    "            if not dt[i, :, 0][j]:\n",
    "                dt[i, :, 0][j:] = 0\n",
    "                \n",
    "    dt_top1 = dt[:, :3, 0].copy()\n",
    "\n",
    "\n",
    "    for state, det in zip(data.state, dt_top1):\n",
    "        state_detections[state] = state_detections.get(state, []) + [det.tolist()]\n",
    "        \n",
    "for state in state_detections:\n",
    "    for trial in range(3):\n",
    "        state_detection_percents[state] = state_detection_percents.get(state, []) + [np.array(state_detections[state])[:, trial].mean()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For Plotting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('detection_results/mixtral_run_results.json', 'r') as f:\n",
    "    mixtral_results = json.load(f)\n",
    "with open('detection_results/qwen_results.json', 'r') as f:\n",
    "    qwen_results = json.load(f)\n",
    "with open('detection_results/yiChat_8_11_incomp_14_16_18_results.json', 'r') as f:\n",
    "    yi_results = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### policy areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "International affairs [289, 213, 170]\n",
      "Government operations and politics [223, 177, 161]\n",
      "Health [347, 230, 193]\n",
      "Armed forces and national security [129, 91, 79]\n",
      "Energy [73, 55, 47]\n",
      "Agriculture and food [116, 86, 73]\n",
      "Immigration [183, 138, 109]\n",
      "Law [42, 32, 27]\n",
      "Transportation and public works [167, 121, 96]\n",
      "Crime and law enforcement [188, 137, 115]\n",
      "Public lands and natural resources [212, 152, 133]\n",
      "Foreign trade and international finance [33, 20, 19]\n",
      "Commerce [67, 53, 46]\n",
      "Water resources development [48, 32, 28]\n",
      "Environmental protection [136, 91, 79]\n",
      "Emergency management [121, 82, 66]\n",
      "Native Americans [68, 44, 40]\n",
      "Congress [43, 26, 25]\n",
      "Labor and employment [65, 47, 41]\n",
      "Economics and public finance [75, 59, 44]\n",
      "Science, technology, communications [77, 52, 46]\n",
      "Finance and financial sector [47, 30, 28]\n",
      "Education [43, 32, 26]\n",
      "Animals [24, 20, 16]\n",
      "Social welfare [28, 18, 18]\n",
      "Civil rights and liberties, minority issues [47, 40, 32]\n"
     ]
    }
   ],
   "source": [
    "pa_list = []\n",
    "for p, det in results['policy_gt'].items():\n",
    "    if det[0]>20:\n",
    "        print(p, det)\n",
    "        pa_list.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "International affairs [0.8393782383419689, 0.7823834196891192, 0.7202072538860104] [162, 151, 139]\n",
      "Government operations and politics [0.7361111111111112, 0.6597222222222222, 0.5972222222222222] [106, 95, 86]\n",
      "Health [0.7565543071161048, 0.6629213483146067, 0.6179775280898876] [202, 177, 165]\n",
      "Armed forces and national security [0.8133333333333334, 0.7333333333333333, 0.72] [61, 55, 54]\n",
      "Energy [0.6039603960396039, 0.5445544554455446, 0.49504950495049505] [61, 55, 50]\n",
      "Agriculture and food [0.6136363636363636, 0.5681818181818182, 0.5454545454545454] [54, 50, 48]\n",
      "Immigration [0.8410596026490066, 0.7615894039735099, 0.7284768211920529] [127, 115, 110]\n",
      "Law [0.7741935483870968, 0.7419354838709677, 0.7419354838709677] [24, 23, 23]\n",
      "Transportation and public works [0.6601307189542484, 0.5751633986928104, 0.5490196078431373] [101, 88, 84]\n",
      "Crime and law enforcement [0.7682119205298014, 0.6754966887417219, 0.6225165562913907] [116, 102, 94]\n",
      "Public lands and natural resources [0.6260162601626016, 0.5284552845528455, 0.4796747967479675] [77, 65, 59]\n",
      "Foreign trade and international finance [0.6521739130434783, 0.6086956521739131, 0.6086956521739131] [15, 14, 14]\n",
      "Taxation [1.0, 0.75, 0.75] [4, 3, 3]\n",
      "Commerce [0.8235294117647058, 0.6862745098039216, 0.6666666666666666] [42, 35, 34]\n",
      "Water resources development [0.7037037037037037, 0.6296296296296297, 0.6296296296296297] [19, 17, 17]\n",
      "Environmental protection [0.6946564885496184, 0.648854961832061, 0.6030534351145038] [91, 85, 79]\n",
      "Families [0.875, 0.875, 0.875] [7, 7, 7]\n",
      "Emergency management [0.7448979591836735, 0.6428571428571429, 0.6224489795918368] [73, 63, 61]\n",
      "Native Americans [0.6764705882352942, 0.6176470588235294, 0.5882352941176471] [23, 21, 20]\n",
      "Congress [0.6585365853658537, 0.6097560975609756, 0.5853658536585366] [27, 25, 24]\n",
      "Commemorations [0.8, 0.6, 0.6] [4, 3, 3]\n",
      "Labor and employment [0.8292682926829268, 0.7317073170731707, 0.6585365853658537] [34, 30, 27]\n",
      "Economics and public finance [1.0, 0.8888888888888888, 0.8518518518518519] [27, 24, 23]\n",
      "Housing and community development [0.5833333333333334, 0.5833333333333334, 0.5833333333333334] [7, 7, 7]\n",
      "Science, technology, communications [0.6956521739130435, 0.6086956521739131, 0.5217391304347826] [32, 28, 24]\n",
      "Finance and financial sector [0.75, 0.59375, 0.5625] [24, 19, 18]\n",
      "Education [0.7878787878787878, 0.696969696969697, 0.6060606060606061] [26, 23, 20]\n",
      "Animals [0.9444444444444444, 0.8333333333333334, 0.7222222222222222] [17, 15, 13]\n",
      "Civil rights and liberties, minority issues [0.7419354838709677, 0.6451612903225806, 0.6451612903225806] [23, 20, 20]\n",
      "Sports and recreation [0.8125, 0.625, 0.5625] [13, 10, 9]\n",
      "Arts, culture, religion [1.0, 1.0, 1.0] [4, 4, 4]\n"
     ]
    }
   ],
   "source": [
    "policy_per = {}\n",
    "for p, per in yi_results['policy_percents'].items():\n",
    "    # if p in pa_list:\n",
    "    print(p, per, yi_results['policy_gt'][p])\n",
    "    policy_per[p] = per + yi_results['policy_gt'][p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(policy_per).transpose().to_csv('detection_results/yi_policy.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### congress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0.9166666666666666, 0.8, 0.6] [55, 48, 36]\n",
      "1 [0.9186351706036745, 0.7716535433070866, 0.6010498687664042] [350, 294, 229]\n",
      "2 [0.9352380952380952, 0.8114285714285714, 0.6628571428571428] [491, 426, 348]\n",
      "3 [0.9284332688588007, 0.7911025145067698, 0.6170212765957447] [480, 409, 319]\n",
      "4 [0.9053497942386831, 0.7716049382716049, 0.6213991769547325] [440, 375, 302]\n",
      "5 [0.9053571428571429, 0.7696428571428572, 0.6267857142857143] [507, 431, 351]\n",
      "6 [0.9215017064846417, 0.7815699658703071, 0.643344709897611] [540, 458, 377]\n",
      "7 [0.9289099526066351, 0.7962085308056872, 0.6635071090047393] [392, 336, 280]\n",
      "8 [0.9347826086956522, 0.8179347826086957, 0.6902173913043478] [344, 301, 254]\n",
      "9 [0.9299516908212561, 0.8043478260869565, 0.6763285024154589] [385, 333, 280]\n",
      "10 [0.875, 0.6833333333333333, 0.55] [105, 82, 66]\n"
     ]
    }
   ],
   "source": [
    "cong_per = {}\n",
    "for p, per in enumerate(qwen_results['cong_percents']):\n",
    "    # if p in pa_list:\n",
    "    print(p, per, qwen_results['cong_gt'][p])\n",
    "    cong_per[p] = per + qwen_results['cong_gt'][p]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NJ [0.7437185929648241, 0.5226130653266332, 0.4371859296482412] [148, 104, 87]\n",
      "CA [0.6891891891891891, 0.481981981981982, 0.40765765765765766] [306, 214, 181]\n",
      "PA [0.640625, 0.4921875, 0.46875] [82, 63, 60]\n",
      "FL [0.6387096774193548, 0.5032258064516129, 0.4] [99, 78, 62]\n",
      "IL [0.6949152542372882, 0.5310734463276836, 0.4576271186440678] [123, 94, 81]\n",
      "MA [0.7169811320754716, 0.5660377358490566, 0.5] [76, 60, 53]\n",
      "TX [0.6266666666666667, 0.4622222222222222, 0.3688888888888889] [141, 104, 83]\n",
      "NY [0.6951219512195121, 0.45934959349593496, 0.36585365853658536] [171, 113, 90]\n",
      "MO [0.6086956521739131, 0.4782608695652174, 0.42028985507246375] [42, 33, 29]\n",
      "SC [0.7777777777777778, 0.5111111111111111, 0.4444444444444444] [35, 23, 20]\n",
      "MD [0.6363636363636364, 0.45454545454545453, 0.375] [56, 40, 33]\n",
      "WI [0.8225806451612904, 0.5806451612903226, 0.4838709677419355] [51, 36, 30]\n",
      "NH [0.65, 0.5, 0.475] [26, 20, 19]\n",
      "VA [0.635036496350365, 0.49635036496350365, 0.41605839416058393] [87, 68, 57]\n",
      "MS [0.6774193548387096, 0.4838709677419355, 0.41935483870967744] [21, 15, 13]\n",
      "NM [0.6463414634146342, 0.4024390243902439, 0.36585365853658536] [53, 33, 30]\n",
      "WA [0.6324786324786325, 0.4358974358974359, 0.358974358974359] [74, 51, 42]\n",
      "TN [0.578125, 0.390625, 0.28125] [37, 25, 18]\n",
      "ME [0.6222222222222222, 0.4444444444444444, 0.4] [28, 20, 18]\n",
      "MN [0.5670103092783505, 0.38144329896907214, 0.3402061855670103] [55, 37, 33]\n",
      "AZ [0.6771653543307087, 0.5118110236220472, 0.4251968503937008] [86, 65, 54]\n",
      "ND [0.5806451612903226, 0.45161290322580644, 0.3870967741935484] [18, 14, 12]\n",
      "GU [0.6153846153846154, 0.46153846153846156, 0.38461538461538464] [8, 6, 5]\n",
      "GA [0.6885245901639344, 0.4918032786885246, 0.32786885245901637] [42, 30, 20]\n",
      "LA [0.7142857142857143, 0.42857142857142855, 0.34285714285714286] [25, 15, 12]\n",
      "CO [0.7142857142857143, 0.5119047619047619, 0.44047619047619047] [60, 43, 37]\n",
      "OR [0.6328125, 0.4609375, 0.375] [81, 59, 48]\n",
      "CT [0.5983606557377049, 0.45901639344262296, 0.4016393442622951] [73, 56, 49]\n",
      "KS [0.6744186046511628, 0.46511627906976744, 0.3953488372093023] [29, 20, 17]\n",
      "NC [0.6538461538461539, 0.4423076923076923, 0.40384615384615385] [68, 46, 42]\n",
      "NE [0.7555555555555555, 0.4222222222222222, 0.37777777777777777] [34, 19, 17]\n",
      "IN [0.6612903225806451, 0.4838709677419355, 0.3870967741935484] [41, 30, 24]\n",
      "WY [0.72, 0.52, 0.44] [36, 26, 22]\n",
      "IA [0.4878048780487805, 0.3902439024390244, 0.2926829268292683] [20, 16, 12]\n",
      "AR [0.5806451612903226, 0.4032258064516129, 0.3225806451612903] [36, 25, 20]\n",
      "OK [0.6851851851851852, 0.5, 0.4444444444444444] [37, 27, 24]\n",
      "UT [0.7454545454545455, 0.4909090909090909, 0.4727272727272727] [41, 27, 26]\n",
      "MI [0.6071428571428571, 0.4166666666666667, 0.4166666666666667] [51, 35, 35]\n",
      "HI [0.6818181818181818, 0.5454545454545454, 0.5] [15, 12, 11]\n",
      "RI [0.6052631578947368, 0.4473684210526316, 0.35964912280701755] [69, 51, 41]\n",
      "SD [0.5882352941176471, 0.4117647058823529, 0.4117647058823529] [10, 7, 7]\n",
      "WV [0.6666666666666666, 0.3939393939393939, 0.36363636363636365] [22, 13, 12]\n",
      "OH [0.5421686746987951, 0.46987951807228917, 0.3855421686746988] [45, 39, 32]\n",
      "MT [0.69, 0.47, 0.4] [69, 47, 40]\n",
      "NV [0.6567164179104478, 0.47761194029850745, 0.3880597014925373] [44, 32, 26]\n",
      "DE [0.7428571428571429, 0.5714285714285714, 0.45714285714285713] [26, 20, 16]\n",
      "VT [0.625, 0.4583333333333333, 0.4166666666666667] [15, 11, 10]\n",
      "ID [0.6744186046511628, 0.4883720930232558, 0.4186046511627907] [29, 21, 18]\n",
      "KY [0.6, 0.425, 0.4] [24, 17, 16]\n",
      "AK [0.7017543859649122, 0.49122807017543857, 0.38596491228070173] [40, 28, 22]\n",
      "PR [0.5, 0.5, 0.5] [2, 2, 2]\n",
      "AS [0.5, 0.25, 0.25] [2, 1, 1]\n",
      "AL [0.78125, 0.65625, 0.46875] [25, 21, 15]\n",
      "DC [0.5, 0.3333333333333333, 0.3333333333333333] [3, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "state_per = {}\n",
    "for p, per in mixtral_results['state_percents'].items():\n",
    "    # if p in pa_list:\n",
    "    print(p, per, mixtral_results['state_gt'][p])\n",
    "    state_per[p] = per + mixtral_results['state_gt'][p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(state_per).transpose().to_csv('detection_results/mixtral_state.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bootstrap Confidence Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "\n",
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    a = 1.0 * np.array(data)\n",
    "    n = len(a[0])\n",
    "    # m, se = np.mean(a, axis=-1), scipy.stats.sem(a, axis=-1)\n",
    "    m, se = np.mean(a, axis=-1), scipy.stats.tstd(a, axis=-1)\n",
    "    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    return [[list(m), list(m-h), list(m+h)], list(se)]\n",
    "    # return [[m, m-h, m+h], se]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'memory/ablation/qwen14_no_deception/detection.json', 'r') as f:\n",
    "        detection = json.load(f)\n",
    "boot = np.array(sk.utils.resample(detection, replace=True, n_samples=detection.__len__(), random_state=42))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### top-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mistral7instructV2: 100%|██████████| 10000/10000 [00:27<00:00, 362.80it/s]\n",
      "qwen7: 100%|██████████| 10000/10000 [00:26<00:00, 372.05it/s]\n",
      "qwen14: 100%|██████████| 10000/10000 [00:27<00:00, 360.53it/s]\n",
      "yi: 100%|██████████| 10000/10000 [00:28<00:00, 354.00it/s]\n",
      "mixtral: 100%|██████████| 10000/10000 [00:28<00:00, 356.83it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "detection_bootstrap_dict = {}\n",
    "confidence_intervals = {}\n",
    "\n",
    "# def bootstrap(model:str):\n",
    "for model in ['qwen', 'yiChat_8_11_14_18', 'mixtral', 'qwen14', 'qwen7', 'mistral7instructV2']:\n",
    "# for model in ['mistral7instructV2', 'qwen7', 'qwen14', 'yi', 'mixtral']:\n",
    "    # with open(f'detection_results/{model}_detection.json', 'r') as f:\n",
    "    with open(f'memory/{model}_run_{split}/detection.json', 'r') as f:\n",
    "        detection = json.load(f)\n",
    "    \n",
    "    detection_mean = [[],[],[]]\n",
    "    if model == 'qwen':\n",
    "        detection_mean.append([])\n",
    "    for i in tqdm(range(10000), desc=model):\n",
    "        boot = sk.utils.resample(detection, replace=True, n_samples=detection.__len__(), random_state=i)\n",
    "        \n",
    "        detection_mean[0].append(np.array(boot)[:, 0].sum(-1).mean())\n",
    "        detection_mean[1].append(np.array(boot)[:, 1].sum(-1).mean())\n",
    "        detection_mean[2].append(np.array(boot)[:, 2].sum(-1).mean())\n",
    "        if model =='qwen':\n",
    "            detection_mean[3].append(np.array(boot)[:, 3].sum(-1).mean())\n",
    "        \n",
    "    \n",
    "    detection_bootstrap_dict[model] = detection_mean\n",
    "    confidence_intervals[model] = [np.array(detection)[:, i].sum(-1).mean() for i in range(3)] + [mean_confidence_interval(detection_bootstrap_dict[model])]\n",
    "    \n",
    "    # with open('detection_results/bootstrap/constant_critic/top2_bootstrap_all_models_bs10k.json', 'w') as f:\n",
    "    #     json.dump(detection_bootstrap_dict, f)\n",
    "    # with open('detection_results/bootstrap/constant_critic/top2_confidence_intervals_bs10k.json', 'w') as f:\n",
    "    #     json.dump(confidence_intervals, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### top-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qwen14_ablate: 100%|██████████| 5000/5000 [00:06<00:00, 720.57it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "top1_detection_bootstrap_dict = {}\n",
    "top1_confidence_intervals = {}\n",
    "\n",
    "# for model in ['qwen', 'yiChat_8_11_14_18', 'mixtral', 'qwen14', 'qwen7', 'mistral7instructV2']:\n",
    "# for model in ['crit_comp_reverse', 'crit_desc_reverse', 'crit_remove_desc', 'rob_ablate_comp', 'rob_bus_bil']:\n",
    "for model in ['qwen14_ablate']:\n",
    "\n",
    "    # if model=='qwen14_ablate':\n",
    "    #     with open(f'memory/ablation/qwen14_ablate_plan/detection_ablate_plan.json', 'r') as f:\n",
    "    #         detection = json.load(f)\n",
    "    # else:\n",
    "    with open(f'memory/constant_critic/smaller_14/qwen/poll_pairs_three_llms/poll_pairs/detection_14_500.json', 'r') as f:\n",
    "        detection = json.load(f)\n",
    "        \n",
    "    detection_mean = [[], [], []]\n",
    "    # if model == 'qwen':\n",
    "    #     detection_mean.append([])\n",
    "    for i in tqdm(range(5000), desc=model):\n",
    "        boot = np.array(sk.utils.resample(detection, replace=True, n_samples=detection.__len__(), random_state=i))\n",
    "        \n",
    "        for i in range(boot[:, :, 0].shape[0]):\n",
    "            for j in range(boot[i, :, 0].shape[0]-2, -1, -1):\n",
    "                if not boot[i, :, 0][j]:\n",
    "                    boot[i, :, 0][j:] = 0\n",
    "\n",
    "        boot_top1 = boot[:, :, 0].copy()\n",
    "        \n",
    "        for i in range(3):\n",
    "            detection_mean[i].append(boot_top1[:, i].mean())\n",
    "        # if model == 'qwen':\n",
    "        #     detection_mean[3].append(boot_top1[:, 3].mean())\n",
    "    \n",
    "    detection = np.array(detection)\n",
    "    for i in range(detection[:, :, 0].shape[0]):\n",
    "        for j in range(detection[i, :, 0].shape[0]-2, -1, -1):\n",
    "            if not detection[i, :, 0][j]:\n",
    "                detection[i, :, 0][j:] = 0\n",
    "                \n",
    "    detection_top1 = detection[:, :, 0].copy()\n",
    "    \n",
    "    # detection_per_trial = []\n",
    "    top1_detection_bootstrap_dict[model] = detection_mean\n",
    "    top1_confidence_intervals[model] = [detection_top1[:, i].mean() for i in range(3)] + [mean_confidence_interval(top1_detection_bootstrap_dict[model])]\n",
    "    \n",
    "    # with open('detection_results/bootstrap/constant_critic/top1_bootstrap_all_models_bs10k.json', 'w') as f:\n",
    "    #     json.dump(top1_detection_bootstrap_dict, f)\n",
    "    with open('detection_results/bootstrap/qwen14_no_deception.json', 'w') as f:\n",
    "        json.dump(top1_confidence_intervals, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'qwen14_ablate': [0.678,\n",
       "  0.456,\n",
       "  0.294,\n",
       "  [[[0.6782556, 0.45628159999999995, 0.2941708],\n",
       "    [0.6371158455654001, 0.4129397793713246, 0.25436164721873494],\n",
       "    [0.7193953544345998, 0.4996234206286753, 0.3339799527812651]],\n",
       "   [0.020984974207000892, 0.02210822598426283, 0.020306247710968655]]]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top1_confidence_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'confidence_intervals' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdetection_results/bootstrap/constant_critic/smaller_7_qwen14_qwen_14_qwen.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      9\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(top1_confidence_intervals, f, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mconfidence_intervals\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'confidence_intervals' is not defined"
     ]
    }
   ],
   "source": [
    "# np.mean(detection_bootstrap_dict['qwen'],axis=-1) - [0.9, 0.7, 0.6]\n",
    "# confidence_intervals = {}\n",
    "\n",
    "# for model in ['qwen14', 'qwen', '14_qwen']:\n",
    "    \n",
    "#     confidence_intervals[model] = mean_confidence_interval(detection_bootstrap_dict[model])\n",
    "\n",
    "with open('detection_results/bootstrap/constant_critic/smaller_7_qwen14_qwen_14_qwen.json', 'w') as f:\n",
    "    json.dump(top1_confidence_intervals, f, indent=4)\n",
    "confidence_intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### States"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qwen 72B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NE: 100%|██████████| 10000/10000 [00:02<00:00, 3863.97it/s]\n",
      "CA: 100%|██████████| 10000/10000 [00:02<00:00, 3440.09it/s]\n",
      "NY: 100%|██████████| 10000/10000 [00:02<00:00, 3626.41it/s]\n",
      "TX: 100%|██████████| 10000/10000 [00:02<00:00, 3790.59it/s]\n",
      "IL: 100%|██████████| 10000/10000 [00:02<00:00, 3686.52it/s]\n",
      "FL: 100%|██████████| 10000/10000 [00:02<00:00, 3704.78it/s]\n",
      "HI: 100%|██████████| 10000/10000 [00:02<00:00, 3950.61it/s]\n",
      "IN: 100%|██████████| 10000/10000 [00:02<00:00, 3824.58it/s]\n",
      "NJ: 100%|██████████| 10000/10000 [00:02<00:00, 3863.57it/s]\n",
      "MI: 100%|██████████| 10000/10000 [00:02<00:00, 3839.12it/s]\n",
      "AR: 100%|██████████| 10000/10000 [00:02<00:00, 3752.22it/s]\n",
      "PA: 100%|██████████| 10000/10000 [00:02<00:00, 3810.28it/s]\n",
      "KY: 100%|██████████| 10000/10000 [00:02<00:00, 3873.44it/s]\n",
      "RI: 100%|██████████| 10000/10000 [00:02<00:00, 3658.71it/s]\n",
      "ME: 100%|██████████| 10000/10000 [00:02<00:00, 3768.16it/s]\n",
      "CT: 100%|██████████| 10000/10000 [00:02<00:00, 3474.06it/s]\n",
      "MO: 100%|██████████| 10000/10000 [00:02<00:00, 3599.13it/s]\n",
      "GA: 100%|██████████| 10000/10000 [00:02<00:00, 3904.38it/s]\n",
      "VA: 100%|██████████| 10000/10000 [00:02<00:00, 3706.99it/s]\n",
      "OH: 100%|██████████| 10000/10000 [00:02<00:00, 3761.89it/s]\n",
      "CO: 100%|██████████| 10000/10000 [00:02<00:00, 3779.11it/s]\n",
      "VT: 100%|██████████| 10000/10000 [00:02<00:00, 3636.72it/s]\n",
      "MT: 100%|██████████| 10000/10000 [00:02<00:00, 3512.06it/s]\n",
      "MN: 100%|██████████| 10000/10000 [00:02<00:00, 3489.12it/s]\n",
      "NC: 100%|██████████| 10000/10000 [00:02<00:00, 3578.39it/s]\n",
      "AZ: 100%|██████████| 10000/10000 [00:02<00:00, 3574.36it/s]\n",
      "DC: 100%|██████████| 10000/10000 [00:02<00:00, 3679.10it/s]\n",
      "WI: 100%|██████████| 10000/10000 [00:02<00:00, 3736.17it/s]\n",
      "AK: 100%|██████████| 10000/10000 [00:02<00:00, 3890.15it/s]\n",
      "NV: 100%|██████████| 10000/10000 [00:02<00:00, 3635.74it/s]\n",
      "NH: 100%|██████████| 10000/10000 [00:02<00:00, 3627.14it/s]\n",
      "OR: 100%|██████████| 10000/10000 [00:02<00:00, 3537.06it/s]\n",
      "KS: 100%|██████████| 10000/10000 [00:02<00:00, 3664.16it/s]\n",
      "ID: 100%|██████████| 10000/10000 [00:02<00:00, 3684.44it/s]\n",
      "UT: 100%|██████████| 10000/10000 [00:02<00:00, 3623.94it/s]\n",
      "IA: 100%|██████████| 10000/10000 [00:02<00:00, 3651.70it/s]\n",
      "DE: 100%|██████████| 10000/10000 [00:02<00:00, 3738.18it/s]\n",
      "MA: 100%|██████████| 10000/10000 [00:02<00:00, 3604.29it/s]\n",
      "WA: 100%|██████████| 10000/10000 [00:02<00:00, 3612.74it/s]\n",
      "ND: 100%|██████████| 10000/10000 [00:02<00:00, 3655.94it/s]\n",
      "TN: 100%|██████████| 10000/10000 [00:02<00:00, 3809.83it/s]\n",
      "MD: 100%|██████████| 10000/10000 [00:02<00:00, 3710.73it/s]\n",
      "MS: 100%|██████████| 10000/10000 [00:02<00:00, 3751.87it/s]\n",
      "AL: 100%|██████████| 10000/10000 [00:02<00:00, 3700.81it/s]\n",
      "SC: 100%|██████████| 10000/10000 [00:02<00:00, 3698.78it/s]\n",
      "NM: 100%|██████████| 10000/10000 [00:02<00:00, 3817.26it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "\n",
    "datamap = {'8_11':'dataset_building/8_11/selected_8_11_policya_state.csv',\n",
    "           'gt112': 'dataset_building/gt112_except14_16_18/gt112_policya_state.csv',\n",
    "           '14_16_18': 'dataset_building/14_16_18/14_16_18_policya_state.csv'}\n",
    "\n",
    "state_detections = {}\n",
    "state_detection_percents = {}\n",
    "\n",
    "state_ci = {}\n",
    "\n",
    "for split in ['14_16_18']:\n",
    "    with open(f'memory/qwen_run_{split}/detection.json', 'r') as f:\n",
    "        dt = np.array(json.load(f))\n",
    "\n",
    "    data = pd.read_csv(datamap[split])\n",
    "    \n",
    "    for i in range(dt[:, :, 0].shape[0]):\n",
    "        for j in range(dt[i, :, 0].shape[0]-2, -1, -1):\n",
    "            if not dt[i, :, 0][j]:\n",
    "                dt[i, :, 0][j:] = 0\n",
    "                \n",
    "    dt_top1 = dt[:, :3, 0].copy()\n",
    "\n",
    "\n",
    "    for state, det in zip(data.state, dt_top1):\n",
    "        state_detections[state] = state_detections.get(state, []) + [det.tolist()]\n",
    "        \n",
    "for state in state_detections:\n",
    "    \n",
    "    \n",
    "    for trial in range(3):\n",
    "        state_detection_percents[state] = state_detection_percents.get(state, []) + [np.array(state_detections[state])[:, trial].mean()]\n",
    "    \n",
    "    \n",
    "    detection_mean = [[], [], []]\n",
    "    boots = []\n",
    "    for i in tqdm(range(10000), desc=state):\n",
    "        boot = np.array(sk.utils.resample(state_detections[state], replace=True, n_samples=state_detections[state].__len__(), random_state=i))\n",
    "        # means.append(boot.mean())\n",
    "        for trial in range(3):\n",
    "            detection_mean[trial] += [boot[:, trial].mean()]\n",
    "        \n",
    "    state_ci[state] = [state_detection_percents[state]] + [mean_confidence_interval(detection_mean)]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('detection_results/bootstrap/states/qwen_14_16_18_states_ci.json', 'w') as f:\n",
    "    json.dump(state_ci, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for state in state_ci:\n",
    "#     state_ci[state] = [i for i in state_ci[state][0]] + [i for i in state_ci[state][1][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_detection_sd = pd.DataFrame(state_ci).transpose()\n",
    "states_detection_sd['deception'] = states_detection_sd[0] - states_detection_sd[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_detection_sd.sort_values('deception').to_csv('states_analysis/states_ranking_14_16_18.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verifying constant critic results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2529, [586, 422, 368, 414, 120])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_upto_14 = 0\n",
    "for i in range(108, 114):\n",
    "    length_upto_14 += full_data[full_data.congress == i].__len__()\n",
    "lengths=[]\n",
    "for i in [114, 115, 116, 117, 118]:\n",
    "    lengths += [full_data[full_data.congress == i].__len__()]\n",
    "    \n",
    "length_upto_14, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('memory/constant_critic/larger/qwen14/detection.json', 'r') as f:\n",
    "#     detection = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting index ranges for 14_16_18 records\n",
    "\n",
    "ranges = [[length_upto_14, length_upto_14+lengths[0]], [length_upto_14+sum(lengths[:2]), length_upto_14+sum(lengths[:3])], [length_upto_14+sum(lengths[:4]), length_upto_14+sum(lengths[:5])]]\n",
    "\n",
    "detection_14 = []\n",
    "for r in ranges:\n",
    "    detection_14 += detection[r[0]:r[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.41899441340782123, 0.5676954268979499)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(detection_14)[:, 0].sum(-1).mean(), np.array(detection)[:, 0].sum(-1).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiments for constant critic with qwen14 show a major drop (above). The above are results for full dataset and 14-18 split.\\\\While simply doing this on the stronger critic script with qwen 72b q5_k_m give higher results for 14-18 splits (aprox 0.76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('memory/constant_critic/prev_yi_main.json', 'r') as f:\n",
    "    main = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4439"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "benefactors_in_main = [main[k]['benefactor'] for k in main]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_company_names = list(full_data.company_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2557"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data_company_names.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_fail_idx = []\n",
    "for idx, (x,y) in enumerate(zip(benefactors_in_main, full_data_company_names)):\n",
    "    if x != y:\n",
    "       match_fail_idx.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1071"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_fail_idx.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "decept",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
